### System Prompt
You are an intelligent programming assistant. Your goal is to take a python file as input and return the first logical
chunk of code.

do not change any of the code, return the original input up until the end of the first logical code chunk.
once finished with giving your answer, use the following token ###AI-END-DOC###

### Example 1 Start
### User Message
import itertools
import pickle
import re
import sys
from collections import defaultdict
from copy import deepcopy
from inspect import signature
from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union

import matplotlib.axes
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import xarray as xr
from pandas.tseries.frequencies import to_offset
from scipy.stats import kurtosis, skew

from .logging import get_logger, raise_if, raise_if_not, raise_log

try:
    from typing import Literal
except ImportError:
    from typing_extensions import Literal

if sys.version_info >= (3, 11):
    from typing import Self
else:
    from typing_extensions import Self

logger = get_logger(__name__)

# dimension names in the DataArray
# the "time" one can be different, if it has a name in the underlying Series/DataFrame.
DIMS = ("time", "component", "sample")

VALID_INDEX_TYPES = (pd.DatetimeIndex, pd.RangeIndex)
STATIC_COV_TAG = "static_covariates"
DEFAULT_GLOBAL_STATIC_COV_NAME = "global_components"
HIERARCHY_TAG = "hierarchy"


class TimeSeries:
    def __init__(self, xa: xr.DataArray):
        """
        Create a TimeSeries from a (well formed) DataArray.
        It is recommended to use the factory methods to create TimeSeries instead.

        See Also
        --------
        TimeSeries.from_dataframe : Create from a :class:`pandas.DataFrame`.
        TimeSeries.from_group_dataframe : Create multiple TimeSeries by groups from a :class:`pandas.DataFrame`.
        TimeSeries.from_series : Create from a :class:`pandas.Series`.
        TimeSeries.from_values : Create from a NumPy :class:`ndarray`.
        TimeSeries.from_times_and_values : Create from a time index and a Numpy :class:`ndarray`.
        TimeSeries.from_csv : Create from a CSV file.
        TimeSeries.from_json : Create from a JSON file.
        TimeSeries.from_xarray : Create from an :class:`xarray.DataArray`.
        """
        raise_if_not(
            isinstance(xa, xr.DataArray),
            "Data must be provided as an xarray DataArray instance. "
            "If you need to create a TimeSeries from another type "
            "(e.g. a DataFrame), look at TimeSeries factory methods "
            "(e.g. TimeSeries.from_dataframe(), "
            "TimeSeries.from_xarray(), TimeSeries.from_values()"
            "TimeSeries.from_times_and_values(), etc...).",
            logger,
        )
        raise_if_not(
            len(xa.shape) == 3,
            f"TimeSeries require DataArray of dimensionality 3 ({DIMS}).",
            logger,
        )

        # Ideally values should be np.float, otherwise certain functionalities like diff()
        # relying on np.nan (which is a float) won't work very properly.
        raise_if_not(
            np.issubdtype(xa.values.dtype, np.number),
            "The time series must contain numeric values only.",
            logger,
        )

        val_dtype = xa.values.dtype
        if not (
            np.issubdtype(val_dtype, np.float64) or np.issubdtype(val_dtype, np.float32)
        ):
            logger.warning(
                "TimeSeries is using a numeric type different from np.float32 or np.float64. "
                "Not all functionalities may work properly. It is recommended casting your data to floating "
                "point numbers before using TimeSeries."
            )

        if xa.dims[-2:] != DIMS[-2:]:
            # The first dimension represents the time and may be named differently.
            raise_log(
                ValueError(
                    "The last two dimensions of the DataArray must be named {}".format(
                        DIMS[-2:]
                    )
                ),
                logger,
            )

        # check that columns/component names are unique
        components = xa.get_index(DIMS[1])
        raise_if_not(
            len(set(components)) == len(components),
            "The components (columns) names must be unique. Provided: {}".format(
                components
            ),
            logger,
        )

        self._time_dim = str(
            xa.dims[0]
        )  # how the time dimension is named; we convert hashable to string

        # The following sorting returns a copy, which we are relying on.
        # As of xarray 0.18.2, this sorting discards the freq of the index for some reason
        # https://github.com/pydata/xarray/issues/5466
        # We sort only if the time axis is not already sorted (monotonically increasing).
        self._xa = self._sort_index(xa, copy=True)

        self._time_index = self._xa.get_index(self._time_dim)

        if not isinstance(self._time_index, VALID_INDEX_TYPES):
            raise_log(
                ValueError(
                    "The time dimension of the DataArray must be indexed either with a DatetimeIndex "
                    "or with an RangeIndex."
                ),
                logger,
            )

        self._has_datetime_index = isinstance(self._time_index, pd.DatetimeIndex)

        if self._has_datetime_index:
            freq_tmp = xa.get_index(
                self._time_dim
            ).freq  # store original freq (see bug of sortby() above).
            self._freq: pd.DateOffset = (
                freq_tmp
                if freq_tmp is not None
                else to_offset(self._xa.get_index(self._time_dim).inferred_freq)
            )
            raise_if(
                self._freq is None,
                "The time index of the provided DataArray is missing the freq attribute, and the frequency could "
                "not be directly inferred. "
                "This probably comes from inconsistent date frequencies with missing dates. "
                "If you know the actual frequency, try setting `fill_missing_dates=True, freq=actual_frequency`. "
                "If not, try setting `fill_missing_dates=True, freq=None` to see if a frequency can be inferred.",
                logger,
            )

            self._freq_str: str = self._freq.freqstr

            # reset freq inside the xarray index (see bug of sortby() above).
            self._xa.get_index(self._time_dim).freq = self._freq

            # We have to check manually if the index is complete for non-empty series. Another way could
            # be to rely on `inferred_freq` being present, but this fails for series of length < 3.
            if len(self._time_index) > 0:
                is_index_complete = (
                    len(
                        pd.date_range(
                            self._time_index.min(),
                            self._time_index.max(),
                            freq=self._freq,
                        ).difference(self._time_index)
                    )
                    == 0
                )

                raise_if_not(
                    is_index_complete,
                    "Not all timestamps seem to be present in the time index. Does "
                    "the series contain holes? If you are using a factory method, "
                    "try specifying `fill_missing_dates=True` "
                    "or specify the `freq` parameter.",
                    logger,
                )
        else:
            self._freq: int = self._time_index.step
            self._freq_str = None

        # check static covariates
        static_covariates = self._xa.attrs.get(STATIC_COV_TAG, None)
        raise_if_not(
            isinstance(static_covariates, (pd.Series, pd.DataFrame))
            or static_covariates is None,
            "`static_covariates` must be either a pandas Series, DataFrame or None",
            logger,
        )
        # check if valid static covariates for multivariate TimeSeries
        if isinstance(static_covariates, pd.DataFrame):
            n_components = len(static_covariates)
            raise_if(
                n_components > 1 and n_components != self.n_components,
                "When passing a multi-row pandas DataFrame, the number of rows must match the number of "
                "components of the TimeSeries object (multi-component/multi-row static covariates must map to each "
                "TimeSeries component).",
                logger,
            )
            static_covariates = static_covariates.copy()
        elif isinstance(static_covariates, pd.Series):
            static_covariates = static_covariates.to_frame().T
        else:  # None
            pass

        # prepare static covariates:
        if static_covariates is not None:
            static_covariates.index = (
                self.components
                if len(static_covariates) == self.n_components
                else [DEFAULT_GLOBAL_STATIC_COV_NAME]
            )
            static_covariates.columns.name = STATIC_COV_TAG
            # convert numerical columns to same dtype as series
            # we get all numerical columns, except those that have right dtype already
            cols_to_cast = static_covariates.select_dtypes(
                include=np.number, exclude=self.dtype
            ).columns

            changes = {col: self.dtype for col in cols_to_cast}
            # Calling astype is costly even when there's no change...
            if len(changes) > 0:
                static_covariates = static_covariates.astype(changes, copy=False)

        # handle hierarchy
        hierarchy = self._xa.attrs.get(HIERARCHY_TAG, None)
        self._top_level_component = None
        self._bottom_level_components = None
        if hierarchy is not None:
            raise_if_not(
                isinstance(hierarchy, dict),
                "The hierarchy must be a dict mapping (non-top) component names to their parent(s) in the hierarchy.",
            )
            # pre-compute grouping informations
            components_set = set(self.components)
            children = set(hierarchy.keys())

            # convert string ancestors to list of strings
            hierarchy = {
                k: ([v] if isinstance(v, str) else v) for k, v in hierarchy.items()
            }

            raise_if_not(
                all(c in components_set for c in children),
                "The keys of the hierarchy must be time series components",
            )
            ancestors = set().union(*hierarchy.values())
            raise_if_not(
                all(a in components_set for a in ancestors),
                "The values of the hierarchy must only contain component names matching those of the series.",
            )
            hierarchy_top = components_set - children
            raise_if_not(
                len(hierarchy_top) == 1,
                "The hierarchy must be such that only one component does "
                + "not appear as a key (the top level component).",
            )
            self._top_level_component = hierarchy_top.pop()
            raise_if_not(
                self._top_level_component in ancestors,
                "Invalid hierarchy. Component {} appears as it should be top-level, but "
                + "does not appear as an ancestor in the hierarchy dict.",
            )
            bottom_level = components_set - ancestors

            # maintain the same order as the original components
            self._bottom_level_components = [
                c for c in self.components if c in bottom_level
            ]

        # Store static covariates and hierarchy in attributes (potentially storing None)
        self._xa = _xarray_with_attrs(self._xa, static_covariates, hierarchy)

    """
    Factory Methods
    ===============
    """

    @classmethod
    def from_xarray(
        cls,
        xa: xr.DataArray,
        fill_missing_dates: Optional[bool] = False,
        freq: Optional[Union[str, int]] = None,
        fillna_value: Optional[float] = None,
    ) -> Self:
        """
        Return a TimeSeries instance built from an xarray DataArray.
        The dimensions of the DataArray have to be (time, component, sample), in this order. The time
        dimension can have an arbitrary name, but component and sample must be named "component" and "sample",
        respectively.

        The first dimension (time), and second dimension (component) must be indexed (i.e., have coordinates).
        The time must be indexed either with a pandas DatetimeIndex, a pandas RangeIndex, or a pandas Index that can
        be converted to a RangeIndex. It is better if the index has no holes; alternatively setting
        `fill_missing_dates` can in some cases solve these issues (filling holes with NaN, or with the provided
        `fillna_value` numeric value, if any).

        If two components have the same name or are not strings, this method will disambiguate the components
        names by appending a suffix of the form "<name>_N" to the N-th column with name "name".
        The component names in the static covariates and hierarchy (if any) are *not* disambiguated.

        Parameters
        ----------
        xa
            The xarray DataArray
        fill_missing_dates
            Optionally, a boolean value indicating whether to fill missing dates (or indices in case of integer index)
            with NaN values. This requires either a provided `freq` or the possibility to infer the frequency from the
            provided timestamps. See :meth:`_fill_missing_dates() <TimeSeries._fill_missing_dates>` for more info.
        freq
            Optionally, a string or integer representing the frequency of the underlying index. This is useful in order
            to fill in missing values if some dates are missing and `fill_missing_dates` is set to `True`.
            If a string, represents the frequency of the pandas DatetimeIndex (see `offset aliases
            <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`_ for more info on
            supported frequencies).
            If an integer, represents the step size of the pandas Index or pandas RangeIndex.
        fillna_value
            Optionally, a numeric value to fill missing values (NaNs) with.

        Returns
        -------
        TimeSeries
            A univariate or multivariate deterministic TimeSeries constructed from the inputs.
        """
        xa_index = xa.get_index(xa.dims[0])

        has_datetime_index = isinstance(xa_index, pd.DatetimeIndex)
        has_range_index = isinstance(xa_index, pd.RangeIndex)
        has_integer_index = not (has_datetime_index or has_range_index)

        has_frequency = (
            has_datetime_index and xa_index.freq is not None
        ) or has_range_index

        # optionally fill missing dates; do it only when there is a DatetimeIndex (and not a RangeIndex)
        if fill_missing_dates:
            xa_ = cls._fill_missing_dates(xa, freq=freq)
        # provided index does not have a freq; using the provided freq
        elif (
            (has_datetime_index or has_integer_index)
            and freq is not None
            and not has_frequency
        ):
            xa_ = cls._restore_xarray_from_frequency(xa, freq=freq)
        # index is an integer index and no freq is provided; try convert it to pd.RangeIndex
        elif has_integer_index and freq is None:
            xa_ = cls._integer_to_range_indexed_xarray(xa)
        else:
            xa_ = xa
        if fillna_value is not None:
            xa_ = xa_.fillna(fillna_value)

        # clean components (columns) names if needed (if names are not unique, or not strings)
        components = xa_.get_index(DIMS[1])
        if len(set(components)) != len(components) or any(
            [not isinstance(s, str) for s in components]
        ):

            def _clean_component_list(columns) -> List[str]:
                # return a list of string containing column names
                # make each column name unique in case some columns have the same names
                clist = columns.to_list()

                # convert everything to string if needed
                for i, column in enumerate(clist):
                    if not isinstance(column, str):
                        clist[i] = str(column)

                has_duplicate = len(set(clist)) != len(clist)
                while has_duplicate:
                    # we may have to loop several times (e.g. we could have columns ["0", "0_1", "0"] and not
                    # noticing when renaming the last "0" into "0_1" that "0_1" already exists...)
                    name_to_occurence = defaultdict(int)
                    for i, column in enumerate(clist):
                        name_to_occurence[clist[i]] += 1

                        if name_to_occurence[clist[i]] > 1:
                            clist[i] = clist[i] + "_{}".format(
                                name_to_occurence[clist[i]] - 1
                            )

                    has_duplicate = len(set(clist)) != len(clist)

                return clist

            time_index_name = xa_.dims[0]
            columns_list = _clean_component_list(components)

            # Note: an option here could be to also rename the component names in the static covariates
            # and/or hierarchy, if any. However, we decide not to do so as those are directly dependent on the
            # component names to work properly, so in case there's any name conflict it's better solved
            # by the user than handled by silent renaming, which can change the way things work.

            # TODO: is there a way to just update the component index without re-creating a new DataArray?
            xa_ = xr.DataArray(
                xa_.values,
                dims=xa_.dims,
                coords={
                    time_index_name: xa_.get_index(time_index_name),
                    DIMS[1]: columns_list,
                },
                attrs=xa_.attrs,
            )

        # We cast the array to float
        if np.issubdtype(xa_.values.dtype, np.float32) or np.issubdtype(
            xa_.values.dtype, np.float64
        ):
            return cls(xa_)
        else:
            return cls(xa_.astype(np.float64))

    def _combine_arrays(
        self,
        other: Union["TimeSeries", xr.DataArray, np.ndarray],
        combine_fn: Callable[[np.ndarray, np.ndarray], np.ndarray],
    ) -> Self:
        """
        This is a helper function that allows us to combine this series with another one,
        directly applying an operation on their underlying numpy arrays.
        """

        if isinstance(other, TimeSeries):
            other_vals = other.data_array(copy=False).values
        elif isinstance(other, xr.DataArray):
            other_vals = other.values
        else:
            other_vals = other

        raise_if_not(
            self._xa.values.shape == other_vals.shape,
            "Attempted to perform operation on two TimeSeries of unequal shapes.",
            logger,
        )
        new_xa = self._xa.copy()
        new_xa.values = combine_fn(new_xa.values, other_vals)
        return self.__class__(new_xa)


### Assistant

import itertools
import pickle
import re
import sys
from collections import defaultdict
from copy import deepcopy
from inspect import signature
from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union
###AI-END-DOC###
### Example 1 End

### Example 2 Start
### User Message
import matplotlib.axes
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import xarray as xr
from pandas.tseries.frequencies import to_offset
from scipy.stats import kurtosis, skew

from .logging import get_logger, raise_if, raise_if_not, raise_log

try:
    from typing import Literal
except ImportError:
    from typing_extensions import Literal

if sys.version_info >= (3, 11):
    from typing import Self
else:
    from typing_extensions import Self

logger = get_logger(__name__)

# dimension names in the DataArray
# the "time" one can be different, if it has a name in the underlying Series/DataFrame.
DIMS = ("time", "component", "sample")

VALID_INDEX_TYPES = (pd.DatetimeIndex, pd.RangeIndex)
STATIC_COV_TAG = "static_covariates"
DEFAULT_GLOBAL_STATIC_COV_NAME = "global_components"
HIERARCHY_TAG = "hierarchy"


class TimeSeries:
    def __init__(self, xa: xr.DataArray):
        """
        Create a TimeSeries from a (well formed) DataArray.
        It is recommended to use the factory methods to create TimeSeries instead.

        See Also
        --------
        TimeSeries.from_dataframe : Create from a :class:`pandas.DataFrame`.
        TimeSeries.from_group_dataframe : Create multiple TimeSeries by groups from a :class:`pandas.DataFrame`.
        TimeSeries.from_series : Create from a :class:`pandas.Series`.
        TimeSeries.from_values : Create from a NumPy :class:`ndarray`.
        TimeSeries.from_times_and_values : Create from a time index and a Numpy :class:`ndarray`.
        TimeSeries.from_csv : Create from a CSV file.
        TimeSeries.from_json : Create from a JSON file.
        TimeSeries.from_xarray : Create from an :class:`xarray.DataArray`.
        """
        raise_if_not(
            isinstance(xa, xr.DataArray),
            "Data must be provided as an xarray DataArray instance. "
            "If you need to create a TimeSeries from another type "
            "(e.g. a DataFrame), look at TimeSeries factory methods "
            "(e.g. TimeSeries.from_dataframe(), "
            "TimeSeries.from_xarray(), TimeSeries.from_values()"
            "TimeSeries.from_times_and_values(), etc...).",
            logger,
        )
        raise_if_not(
            len(xa.shape) == 3,
            f"TimeSeries require DataArray of dimensionality 3 ({DIMS}).",
            logger,
        )

        # Ideally values should be np.float, otherwise certain functionalities like diff()
        # relying on np.nan (which is a float) won't work very properly.
        raise_if_not(
            np.issubdtype(xa.values.dtype, np.number),
            "The time series must contain numeric values only.",
            logger,
        )

        val_dtype = xa.values.dtype
        if not (
            np.issubdtype(val_dtype, np.float64) or np.issubdtype(val_dtype, np.float32)
        ):
            logger.warning(
                "TimeSeries is using a numeric type different from np.float32 or np.float64. "
                "Not all functionalities may work properly. It is recommended casting your data to floating "
                "point numbers before using TimeSeries."
            )

        if xa.dims[-2:] != DIMS[-2:]:
            # The first dimension represents the time and may be named differently.
            raise_log(
                ValueError(
                    "The last two dimensions of the DataArray must be named {}".format(
                        DIMS[-2:]
                    )
                ),
                logger,
            )

        # check that columns/component names are unique
        components = xa.get_index(DIMS[1])
        raise_if_not(
            len(set(components)) == len(components),
            "The components (columns) names must be unique. Provided: {}".format(
                components
            ),
            logger,
        )

        self._time_dim = str(
            xa.dims[0]
        )  # how the time dimension is named; we convert hashable to string

        # The following sorting returns a copy, which we are relying on.
        # As of xarray 0.18.2, this sorting discards the freq of the index for some reason
        # https://github.com/pydata/xarray/issues/5466
        # We sort only if the time axis is not already sorted (monotonically increasing).
        self._xa = self._sort_index(xa, copy=True)

        self._time_index = self._xa.get_index(self._time_dim)

        if not isinstance(self._time_index, VALID_INDEX_TYPES):
            raise_log(
                ValueError(
                    "The time dimension of the DataArray must be indexed either with a DatetimeIndex "
                    "or with an RangeIndex."
                ),
                logger,
            )

        self._has_datetime_index = isinstance(self._time_index, pd.DatetimeIndex)

        if self._has_datetime_index:
            freq_tmp = xa.get_index(
                self._time_dim
            ).freq  # store original freq (see bug of sortby() above).
            self._freq: pd.DateOffset = (
                freq_tmp
                if freq_tmp is not None
                else to_offset(self._xa.get_index(self._time_dim).inferred_freq)
            )
            raise_if(
                self._freq is None,
                "The time index of the provided DataArray is missing the freq attribute, and the frequency could "
                "not be directly inferred. "
                "This probably comes from inconsistent date frequencies with missing dates. "
                "If you know the actual frequency, try setting `fill_missing_dates=True, freq=actual_frequency`. "
                "If not, try setting `fill_missing_dates=True, freq=None` to see if a frequency can be inferred.",
                logger,
            )

            self._freq_str: str = self._freq.freqstr

            # reset freq inside the xarray index (see bug of sortby() above).
            self._xa.get_index(self._time_dim).freq = self._freq

            # We have to check manually if the index is complete for non-empty series. Another way could
            # be to rely on `inferred_freq` being present, but this fails for series of length < 3.
            if len(self._time_index) > 0:
                is_index_complete = (
                    len(
                        pd.date_range(
                            self._time_index.min(),
                            self._time_index.max(),
                            freq=self._freq,
                        ).difference(self._time_index)
                    )
                    == 0
                )

                raise_if_not(
                    is_index_complete,
                    "Not all timestamps seem to be present in the time index. Does "
                    "the series contain holes? If you are using a factory method, "
                    "try specifying `fill_missing_dates=True` "
                    "or specify the `freq` parameter.",
                    logger,
                )
        else:
            self._freq: int = self._time_index.step
            self._freq_str = None

        # check static covariates
        static_covariates = self._xa.attrs.get(STATIC_COV_TAG, None)
        raise_if_not(
            isinstance(static_covariates, (pd.Series, pd.DataFrame))
            or static_covariates is None,
            "`static_covariates` must be either a pandas Series, DataFrame or None",
            logger,
        )
        # check if valid static covariates for multivariate TimeSeries
        if isinstance(static_covariates, pd.DataFrame):
            n_components = len(static_covariates)
            raise_if(
                n_components > 1 and n_components != self.n_components,
                "When passing a multi-row pandas DataFrame, the number of rows must match the number of "
                "components of the TimeSeries object (multi-component/multi-row static covariates must map to each "
                "TimeSeries component).",
                logger,
            )
            static_covariates = static_covariates.copy()
        elif isinstance(static_covariates, pd.Series):
            static_covariates = static_covariates.to_frame().T
        else:  # None
            pass

        # prepare static covariates:
        if static_covariates is not None:
            static_covariates.index = (
                self.components
                if len(static_covariates) == self.n_components
                else [DEFAULT_GLOBAL_STATIC_COV_NAME]
            )
            static_covariates.columns.name = STATIC_COV_TAG
            # convert numerical columns to same dtype as series
            # we get all numerical columns, except those that have right dtype already
            cols_to_cast = static_covariates.select_dtypes(
                include=np.number, exclude=self.dtype
            ).columns

            changes = {col: self.dtype for col in cols_to_cast}
            # Calling astype is costly even when there's no change...
            if len(changes) > 0:
                static_covariates = static_covariates.astype(changes, copy=False)

        # handle hierarchy
        hierarchy = self._xa.attrs.get(HIERARCHY_TAG, None)
        self._top_level_component = None
        self._bottom_level_components = None
        if hierarchy is not None:
            raise_if_not(
                isinstance(hierarchy, dict),
                "The hierarchy must be a dict mapping (non-top) component names to their parent(s) in the hierarchy.",
            )
            # pre-compute grouping informations
            components_set = set(self.components)
            children = set(hierarchy.keys())

            # convert string ancestors to list of strings
            hierarchy = {
                k: ([v] if isinstance(v, str) else v) for k, v in hierarchy.items()
            }

            raise_if_not(
                all(c in components_set for c in children),
                "The keys of the hierarchy must be time series components",
            )
            ancestors = set().union(*hierarchy.values())
            raise_if_not(
                all(a in components_set for a in ancestors),
                "The values of the hierarchy must only contain component names matching those of the series.",
            )
            hierarchy_top = components_set - children
            raise_if_not(
                len(hierarchy_top) == 1,
                "The hierarchy must be such that only one component does "
                + "not appear as a key (the top level component).",
            )
            self._top_level_component = hierarchy_top.pop()
            raise_if_not(
                self._top_level_component in ancestors,
                "Invalid hierarchy. Component {} appears as it should be top-level, but "
                + "does not appear as an ancestor in the hierarchy dict.",
            )
            bottom_level = components_set - ancestors

            # maintain the same order as the original components
            self._bottom_level_components = [
                c for c in self.components if c in bottom_level
            ]

        # Store static covariates and hierarchy in attributes (potentially storing None)
        self._xa = _xarray_with_attrs(self._xa, static_covariates, hierarchy)

    """
    Factory Methods
    ===============
    """

    @classmethod
    def from_xarray(
        cls,
        xa: xr.DataArray,
        fill_missing_dates: Optional[bool] = False,
        freq: Optional[Union[str, int]] = None,
        fillna_value: Optional[float] = None,
    ) -> Self:
        """
        Return a TimeSeries instance built from an xarray DataArray.
        The dimensions of the DataArray have to be (time, component, sample), in this order. The time
        dimension can have an arbitrary name, but component and sample must be named "component" and "sample",
        respectively.

        The first dimension (time), and second dimension (component) must be indexed (i.e., have coordinates).
        The time must be indexed either with a pandas DatetimeIndex, a pandas RangeIndex, or a pandas Index that can
        be converted to a RangeIndex. It is better if the index has no holes; alternatively setting
        `fill_missing_dates` can in some cases solve these issues (filling holes with NaN, or with the provided
        `fillna_value` numeric value, if any).

        If two components have the same name or are not strings, this method will disambiguate the components
        names by appending a suffix of the form "<name>_N" to the N-th column with name "name".
        The component names in the static covariates and hierarchy (if any) are *not* disambiguated.

        Parameters
        ----------
        xa
            The xarray DataArray
        fill_missing_dates
            Optionally, a boolean value indicating whether to fill missing dates (or indices in case of integer index)
            with NaN values. This requires either a provided `freq` or the possibility to infer the frequency from the
            provided timestamps. See :meth:`_fill_missing_dates() <TimeSeries._fill_missing_dates>` for more info.
        freq
            Optionally, a string or integer representing the frequency of the underlying index. This is useful in order
            to fill in missing values if some dates are missing and `fill_missing_dates` is set to `True`.
            If a string, represents the frequency of the pandas DatetimeIndex (see `offset aliases
            <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`_ for more info on
            supported frequencies).
            If an integer, represents the step size of the pandas Index or pandas RangeIndex.
        fillna_value
            Optionally, a numeric value to fill missing values (NaNs) with.

        Returns
        -------
        TimeSeries
            A univariate or multivariate deterministic TimeSeries constructed from the inputs.
        """
        xa_index = xa.get_index(xa.dims[0])

        has_datetime_index = isinstance(xa_index, pd.DatetimeIndex)
        has_range_index = isinstance(xa_index, pd.RangeIndex)
        has_integer_index = not (has_datetime_index or has_range_index)

        has_frequency = (
            has_datetime_index and xa_index.freq is not None
        ) or has_range_index

        # optionally fill missing dates; do it only when there is a DatetimeIndex (and not a RangeIndex)
        if fill_missing_dates:
            xa_ = cls._fill_missing_dates(xa, freq=freq)
        # provided index does not have a freq; using the provided freq
        elif (
            (has_datetime_index or has_integer_index)
            and freq is not None
            and not has_frequency
        ):
            xa_ = cls._restore_xarray_from_frequency(xa, freq=freq)
        # index is an integer index and no freq is provided; try convert it to pd.RangeIndex
        elif has_integer_index and freq is None:
            xa_ = cls._integer_to_range_indexed_xarray(xa)
        else:
            xa_ = xa
        if fillna_value is not None:
            xa_ = xa_.fillna(fillna_value)

        # clean components (columns) names if needed (if names are not unique, or not strings)
        components = xa_.get_index(DIMS[1])
        if len(set(components)) != len(components) or any(
            [not isinstance(s, str) for s in components]
        ):

            def _clean_component_list(columns) -> List[str]:
                # return a list of string containing column names
                # make each column name unique in case some columns have the same names
                clist = columns.to_list()

                # convert everything to string if needed
                for i, column in enumerate(clist):
                    if not isinstance(column, str):
                        clist[i] = str(column)

                has_duplicate = len(set(clist)) != len(clist)
                while has_duplicate:
                    # we may have to loop several times (e.g. we could have columns ["0", "0_1", "0"] and not
                    # noticing when renaming the last "0" into "0_1" that "0_1" already exists...)
                    name_to_occurence = defaultdict(int)
                    for i, column in enumerate(clist):
                        name_to_occurence[clist[i]] += 1

                        if name_to_occurence[clist[i]] > 1:
                            clist[i] = clist[i] + "_{}".format(
                                name_to_occurence[clist[i]] - 1
                            )

                    has_duplicate = len(set(clist)) != len(clist)

                return clist

            time_index_name = xa_.dims[0]
            columns_list = _clean_component_list(components)

            # Note: an option here could be to also rename the component names in the static covariates
            # and/or hierarchy, if any. However, we decide not to do so as those are directly dependent on the
            # component names to work properly, so in case there's any name conflict it's better solved
            # by the user than handled by silent renaming, which can change the way things work.

            # TODO: is there a way to just update the component index without re-creating a new DataArray?
            xa_ = xr.DataArray(
                xa_.values,
                dims=xa_.dims,
                coords={
                    time_index_name: xa_.get_index(time_index_name),
                    DIMS[1]: columns_list,
                },
                attrs=xa_.attrs,
            )

        # We cast the array to float
        if np.issubdtype(xa_.values.dtype, np.float32) or np.issubdtype(
            xa_.values.dtype, np.float64
        ):
            return cls(xa_)
        else:
            return cls(xa_.astype(np.float64))

    @classmethod
    def from_csv(
        cls,
        filepath_or_buffer,
        time_col: Optional[str] = None,
        value_cols: Optional[Union[List[str], str]] = None,
        fill_missing_dates: Optional[bool] = False,
        freq: Optional[Union[str, int]] = None,
        fillna_value: Optional[float] = None,
        static_covariates: Optional[Union[pd.Series, pd.DataFrame]] = None,
        hierarchy: Optional[Dict] = None,
        **kwargs,
    ) -> Self:
        """
        Build a deterministic TimeSeries instance built from a single CSV file.
        One column can be used to represent the time (if not present, the time index will be a RangeIndex)
        and a list of columns `value_cols` can be used to indicate the values for this time series.

        Parameters
        ----------
        filepath_or_buffer
            The path to the CSV file, or the file object; consistent with the argument of `pandas.read_csv` function
        time_col
            The time column name. If set, the column will be cast to a pandas DatetimeIndex (if it contains
            timestamps) or a RangeIndex (if it contains integers).
            If not set, the pandas RangeIndex will be used.
        value_cols
            A string or list of strings representing the value column(s) to be extracted from the CSV file. If set to
            `None`, all columns from the CSV file will be used (except for the time_col, if specified)
        fill_missing_dates
            Optionally, a boolean value indicating whether to fill missing dates (or indices in case of integer index)
            with NaN values. This requires either a provided `freq` or the possibility to infer the frequency from the
            provided timestamps. See :meth:`_fill_missing_dates() <TimeSeries._fill_missing_dates>` for more info.
        freq
            Optionally, a string or integer representing the frequency of the underlying index. This is useful in order
            to fill in missing values if some dates are missing and `fill_missing_dates` is set to `True`.
            If a string, represents the frequency of the pandas DatetimeIndex (see `offset aliases
            <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`_ for more info on
            supported frequencies).
            If an integer, represents the step size of the pandas Index or pandas RangeIndex.
        fillna_value
            Optionally, a numeric value to fill missing values (NaNs) with.
        static_covariates
            Optionally, a set of static covariates to be added to the TimeSeries. Either a pandas Series or a pandas
            DataFrame. If a Series, the index represents the static variables. The covariates are globally 'applied'
            to all components of the TimeSeries. If a DataFrame, the columns represent the static variables and the
            rows represent the components of the uni/multivariate TimeSeries. If a single-row DataFrame, the covariates
            are globally 'applied' to all components of the TimeSeries. If a multi-row DataFrame, the number of
            rows must match the number of components of the TimeSeries (in this case, the number of columns in the CSV
            file). This adds control for component-specific static covariates.
        hierarchy
            Optionally, a dictionary describing the grouping(s) of the time series. The keys are component names, and
            for a given component name `c`, the value is a list of component names that `c` "belongs" to. For instance,
            if there is a `total` component, split both in two divisions `d1` and `d2` and in two regions `r1` and `r2`,
            and four products `d1r1` (in division `d1` and region `r1`), `d2r1`, `d1r2` and `d2r2`, the hierarchy would
            be encoded as follows.

            .. highlight:: python
            .. code-block:: python

                hierarchy={
                    "d1r1": ["d1", "r1"],
                    "d1r2": ["d1", "r2"],
                    "d2r1": ["d2", "r1"],
                    "d2r2": ["d2", "r2"],
                    "d1": ["total"],
                    "d2": ["total"],
                    "r1": ["total"],
                    "r2": ["total"]
                }
            ..
            The hierarchy can be used to reconcile forecasts (so that the sums of the forecasts at
            different levels are consistent), see `hierarchical reconciliation
            <https://unit8co.github.io/darts/generated_api/darts.dataprocessing.transformers.reconciliation.html>`_.

        **kwargs
            Optional arguments to be passed to `pandas.read_csv` function

        Returns
        -------
        TimeSeries
            A univariate or multivariate deterministic TimeSeries constructed from the inputs.
        """

        df = pd.read_csv(filepath_or_buffer=filepath_or_buffer, **kwargs)
        return cls.from_dataframe(
            df=df,
            time_col=time_col,
            value_cols=value_cols,
            fill_missing_dates=fill_missing_dates,
            freq=freq,
            fillna_value=fillna_value,
            static_covariates=static_covariates,
            hierarchy=hierarchy,
        )

    @classmethod
    def from_dataframe(
        cls,
        df: pd.DataFrame,
        time_col: Optional[str] = None,
        value_cols: Optional[Union[List[str], str]] = None,
        fill_missing_dates: Optional[bool] = False,
        freq: Optional[Union[str, int]] = None,
        fillna_value: Optional[float] = None,
        static_covariates: Optional[Union[pd.Series, pd.DataFrame]] = None,
        hierarchy: Optional[Dict] = None,
    ) -> Self:
        """
        Build a deterministic TimeSeries instance built from a selection of columns of a DataFrame.
        One column (or the DataFrame index) has to represent the time,
        and a list of columns `value_cols` has to represent the values for this time series.

        Parameters
        ----------
        df
            The DataFrame
        time_col
            The time column name. If set, the column will be cast to a pandas DatetimeIndex (if it contains
            timestamps) or a RangeIndex (if it contains integers).
            If not set, the DataFrame index will be used. In this case the DataFrame must contain an index that is
            either a pandas DatetimeIndex, a pandas RangeIndex, or a pandas Index that can be converted to a
            RangeIndex. It is better if the index has no holes; alternatively setting `fill_missing_dates` can in some
            cases solve these issues (filling holes with NaN, or with the provided `fillna_value` numeric value, if
            any).
        value_cols
            A string or list of strings representing the value column(s) to be extracted from the DataFrame. If set to
            `None`, the whole DataFrame will be used.
        fill_missing_dates
            Optionally, a boolean value indicating whether to fill missing dates (or indices in case of integer index)
            with NaN values. This requires either a provided `freq` or the possibility to infer the frequency from the
            provided timestamps. See :meth:`_fill_missing_dates() <TimeSeries._fill_missing_dates>` for more info.
        freq
            Optionally, a string or integer representing the frequency of the underlying index. This is useful in order
            to fill in missing values if some dates are missing and `fill_missing_dates` is set to `True`.
            If a string, represents the frequency of the pandas DatetimeIndex (see `offset aliases
            <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`_ for more info on
            supported frequencies).
            If an integer, represents the step size of the pandas Index or pandas RangeIndex.
        fillna_value
            Optionally, a numeric value to fill missing values (NaNs) with.
        static_covariates
            Optionally, a set of static covariates to be added to the TimeSeries. Either a pandas Series or a pandas
            DataFrame. If a Series, the index represents the static variables. The covariates are globally 'applied'
            to all components of the TimeSeries. If a DataFrame, the columns represent the static variables and the
            rows represent the components of the uni/multivariate TimeSeries. If a single-row DataFrame, the covariates
            are globally 'applied' to all components of the TimeSeries. If a multi-row DataFrame, the number of
            rows must match the number of components of the TimeSeries (in this case, the number of columns in
            ``value_cols``). This adds control for component-specific static covariates.
        hierarchy
            Optionally, a dictionary describing the grouping(s) of the time series. The keys are component names, and
            for a given component name `c`, the value is a list of component names that `c` "belongs" to. For instance,
            if there is a `total` component, split both in two divisions `d1` and `d2` and in two regions `r1` and `r2`,
            and four products `d1r1` (in division `d1` and region `r1`), `d2r1`, `d1r2` and `d2r2`, the hierarchy would
            be encoded as follows.

            .. highlight:: python
            .. code-block:: python

                hierarchy={
                    "d1r1": ["d1", "r1"],
                    "d1r2": ["d1", "r2"],
                    "d2r1": ["d2", "r1"],
                    "d2r2": ["d2", "r2"],
                    "d1": ["total"],
                    "d2": ["total"],
                    "r1": ["total"],
                    "r2": ["total"]
                }
            ..
            The hierarchy can be used to reconcile forecasts (so that the sums of the forecasts at
            different levels are consistent), see `hierarchical reconciliation
            <https://unit8co.github.io/darts/generated_api/darts.dataprocessing.transformers.reconciliation.html>`_.

        Returns
        -------
        TimeSeries
            A univariate or multivariate deterministic TimeSeries constructed from the inputs.
        """

        # get values
        if value_cols is None:
            series_df = df.loc[:, df.columns != time_col]
        else:
            if isinstance(value_cols, str):
                value_cols = [value_cols]
            series_df = df[value_cols]

        # get time index
        if time_col:
            if time_col not in df.columns:
                raise_log(AttributeError(f"time_col='{time_col}' is not present."))

            time_index = pd.Index([])
            time_col_vals = df[time_col]

            if np.issubdtype(time_col_vals.dtype, object):
                # Try to convert to integers if needed
                try:
                    time_col_vals = time_col_vals.astype(int)
                except ValueError:
                    pass

            if np.issubdtype(time_col_vals.dtype, np.integer):
                # We have to check all integers appear only once to have a valid index
                raise_if(
                    time_col_vals.duplicated().any(),
                    "The provided integer time index column contains duplicate values.",
                )

                # Temporarily use an integer Index to sort the values, and replace by a
                # RangeIndex in `TimeSeries.from_xarray()`
                time_index = pd.Index(time_col_vals)

            elif np.issubdtype(time_col_vals.dtype, object):
                # The integer conversion failed; try datetimes
                try:
                    time_index = pd.DatetimeIndex(time_col_vals)
                except ValueError:
                    raise_log(
                        AttributeError(
                            "'time_col' is of 'object' dtype but doesn't contain valid timestamps"
                        )
                    )
            elif np.issubdtype(time_col_vals.dtype, np.datetime64):
                time_index = pd.DatetimeIndex(time_col_vals)
            else:
                raise_log(
                    AttributeError(
                        "Invalid type of `time_col`: it needs to be of either 'str', 'datetime' or 'int' dtype."
                    )
                )
            time_index.name = time_col
        else:
            raise_if_not(
                isinstance(df.index, VALID_INDEX_TYPES)
                or np.issubdtype(df.index.dtype, np.integer),
                "If time_col is not specified, the DataFrame must be indexed either with "
                "a DatetimeIndex, a RangeIndex, or an integer Index that can be converted into a RangeIndex",
                logger,
            )
            # BUGFIX : force time-index to be timezone naive as xarray doesn't support it
            # pandas.DataFrame loses the tz information if it's not its index
            if isinstance(df.index, pd.DatetimeIndex) and df.index.tz is not None:
                logger.warning(
                    "The provided DatetimeIndex was associated with a timezone, which is currently not supported "
                    "by xarray. To avoid unexpected behaviour, the tz information was removed. Consider calling "
                    f"`ts.time_index.tz_localize({df.index.tz})` when exporting the results."
                    "To plot the series with the right time steps, consider setting the matplotlib.pyplot "
                    "`rcParams['timezone']` parameter to automatically convert the time axis back to the "
                    "original timezone."
                )
                time_index = df.index.tz_localize(None)
            else:
                time_index = df.index

        if not time_index.name:
            time_index.name = time_col if time_col else DIMS[0]

        if series_df.columns.name:
            series_df.columns.name = None

        xa = xr.DataArray(
            series_df.values[:, :, np.newaxis],
            dims=(time_index.name,) + DIMS[-2:],
            coords={time_index.name: time_index, DIMS[1]: series_df.columns},
            attrs={STATIC_COV_TAG: static_covariates, HIERARCHY_TAG: hierarchy},
        )

        return cls.from_xarray(
            xa=xa,
            fill_missing_dates=fill_missing_dates,
            freq=freq,
            fillna_value=fillna_value,
        )


### Assistant
import matplotlib.axes
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import xarray as xr
from pandas.tseries.frequencies import to_offset
from scipy.stats import kurtosis, skew
###AI-END-DOC###
### Example 2 End

### Example 3 Start
### User Message

class TimeSeries:
    def __init__(self, xa: xr.DataArray):
        """
        Create a TimeSeries from a (well formed) DataArray.
        It is recommended to use the factory methods to create TimeSeries instead.

        See Also
        --------
        TimeSeries.from_dataframe : Create from a :class:`pandas.DataFrame`.
        TimeSeries.from_group_dataframe : Create multiple TimeSeries by groups from a :class:`pandas.DataFrame`.
        TimeSeries.from_series : Create from a :class:`pandas.Series`.
        TimeSeries.from_values : Create from a NumPy :class:`ndarray`.
        TimeSeries.from_times_and_values : Create from a time index and a Numpy :class:`ndarray`.
        TimeSeries.from_csv : Create from a CSV file.
        TimeSeries.from_json : Create from a JSON file.
        TimeSeries.from_xarray : Create from an :class:`xarray.DataArray`.
        """
        raise_if_not(
            isinstance(xa, xr.DataArray),
            "Data must be provided as an xarray DataArray instance. "
            "If you need to create a TimeSeries from another type "
            "(e.g. a DataFrame), look at TimeSeries factory methods "
            "(e.g. TimeSeries.from_dataframe(), "
            "TimeSeries.from_xarray(), TimeSeries.from_values()"
            "TimeSeries.from_times_and_values(), etc...).",
            logger,
        )
        raise_if_not(
            len(xa.shape) == 3,
            f"TimeSeries require DataArray of dimensionality 3 ({DIMS}).",
            logger,
        )

        # Ideally values should be np.float, otherwise certain functionalities like diff()
        # relying on np.nan (which is a float) won't work very properly.
        raise_if_not(
            np.issubdtype(xa.values.dtype, np.number),
            "The time series must contain numeric values only.",
            logger,
        )

        val_dtype = xa.values.dtype
        if not (
            np.issubdtype(val_dtype, np.float64) or np.issubdtype(val_dtype, np.float32)
        ):
            logger.warning(
                "TimeSeries is using a numeric type different from np.float32 or np.float64. "
                "Not all functionalities may work properly. It is recommended casting your data to floating "
                "point numbers before using TimeSeries."
            )

        if xa.dims[-2:] != DIMS[-2:]:
            # The first dimension represents the time and may be named differently.
            raise_log(
                ValueError(
                    "The last two dimensions of the DataArray must be named {}".format(
                        DIMS[-2:]
                    )
                ),
                logger,
            )

        # check that columns/component names are unique
        components = xa.get_index(DIMS[1])
        raise_if_not(
            len(set(components)) == len(components),
            "The components (columns) names must be unique. Provided: {}".format(
                components
            ),
            logger,
        )

        self._time_dim = str(
            xa.dims[0]
        )  # how the time dimension is named; we convert hashable to string

        # The following sorting returns a copy, which we are relying on.
        # As of xarray 0.18.2, this sorting discards the freq of the index for some reason
        # https://github.com/pydata/xarray/issues/5466
        # We sort only if the time axis is not already sorted (monotonically increasing).
        self._xa = self._sort_index(xa, copy=True)

        self._time_index = self._xa.get_index(self._time_dim)

        if not isinstance(self._time_index, VALID_INDEX_TYPES):
            raise_log(
                ValueError(
                    "The time dimension of the DataArray must be indexed either with a DatetimeIndex "
                    "or with an RangeIndex."
                ),
                logger,
            )

        self._has_datetime_index = isinstance(self._time_index, pd.DatetimeIndex)

        if self._has_datetime_index:
            freq_tmp = xa.get_index(
                self._time_dim
            ).freq  # store original freq (see bug of sortby() above).
            self._freq: pd.DateOffset = (
                freq_tmp
                if freq_tmp is not None
                else to_offset(self._xa.get_index(self._time_dim).inferred_freq)
            )
            raise_if(
                self._freq is None,
                "The time index of the provided DataArray is missing the freq attribute, and the frequency could "
                "not be directly inferred. "
                "This probably comes from inconsistent date frequencies with missing dates. "
                "If you know the actual frequency, try setting `fill_missing_dates=True, freq=actual_frequency`. "
                "If not, try setting `fill_missing_dates=True, freq=None` to see if a frequency can be inferred.",
                logger,
            )

            self._freq_str: str = self._freq.freqstr

            # reset freq inside the xarray index (see bug of sortby() above).
            self._xa.get_index(self._time_dim).freq = self._freq

            # We have to check manually if the index is complete for non-empty series. Another way could
            # be to rely on `inferred_freq` being present, but this fails for series of length < 3.
            if len(self._time_index) > 0:
                is_index_complete = (
                    len(
                        pd.date_range(
                            self._time_index.min(),
                            self._time_index.max(),
                            freq=self._freq,
                        ).difference(self._time_index)
                    )
                    == 0
                )

                raise_if_not(
                    is_index_complete,
                    "Not all timestamps seem to be present in the time index. Does "
                    "the series contain holes? If you are using a factory method, "
                    "try specifying `fill_missing_dates=True` "
                    "or specify the `freq` parameter.",
                    logger,
                )
        else:
            self._freq: int = self._time_index.step
            self._freq_str = None

        # check static covariates
        static_covariates = self._xa.attrs.get(STATIC_COV_TAG, None)
        raise_if_not(
            isinstance(static_covariates, (pd.Series, pd.DataFrame))
            or static_covariates is None,
            "`static_covariates` must be either a pandas Series, DataFrame or None",
            logger,
        )
        # check if valid static covariates for multivariate TimeSeries
        if isinstance(static_covariates, pd.DataFrame):
            n_components = len(static_covariates)
            raise_if(
                n_components > 1 and n_components != self.n_components,
                "When passing a multi-row pandas DataFrame, the number of rows must match the number of "
                "components of the TimeSeries object (multi-component/multi-row static covariates must map to each "
                "TimeSeries component).",
                logger,
            )
            static_covariates = static_covariates.copy()
        elif isinstance(static_covariates, pd.Series):
            static_covariates = static_covariates.to_frame().T
        else:  # None
            pass

        # prepare static covariates:
        if static_covariates is not None:
            static_covariates.index = (
                self.components
                if len(static_covariates) == self.n_components
                else [DEFAULT_GLOBAL_STATIC_COV_NAME]
            )
            static_covariates.columns.name = STATIC_COV_TAG
            # convert numerical columns to same dtype as series
            # we get all numerical columns, except those that have right dtype already
            cols_to_cast = static_covariates.select_dtypes(
                include=np.number, exclude=self.dtype
            ).columns

            changes = {col: self.dtype for col in cols_to_cast}
            # Calling astype is costly even when there's no change...
            if len(changes) > 0:
                static_covariates = static_covariates.astype(changes, copy=False)

        # handle hierarchy
        hierarchy = self._xa.attrs.get(HIERARCHY_TAG, None)
        self._top_level_component = None
        self._bottom_level_components = None
        if hierarchy is not None:
            raise_if_not(
                isinstance(hierarchy, dict),
                "The hierarchy must be a dict mapping (non-top) component names to their parent(s) in the hierarchy.",
            )
            # pre-compute grouping informations
            components_set = set(self.components)
            children = set(hierarchy.keys())

            # convert string ancestors to list of strings
            hierarchy = {
                k: ([v] if isinstance(v, str) else v) for k, v in hierarchy.items()
            }

            raise_if_not(
                all(c in components_set for c in children),
                "The keys of the hierarchy must be time series components",
            )
            ancestors = set().union(*hierarchy.values())
            raise_if_not(
                all(a in components_set for a in ancestors),
                "The values of the hierarchy must only contain component names matching those of the series.",
            )
            hierarchy_top = components_set - children
            raise_if_not(
                len(hierarchy_top) == 1,
                "The hierarchy must be such that only one component does "
                + "not appear as a key (the top level component).",
            )
            self._top_level_component = hierarchy_top.pop()
            raise_if_not(
                self._top_level_component in ancestors,
                "Invalid hierarchy. Component {} appears as it should be top-level, but "
                + "does not appear as an ancestor in the hierarchy dict.",
            )
            bottom_level = components_set - ancestors

            # maintain the same order as the original components
            self._bottom_level_components = [
                c for c in self.components if c in bottom_level
            ]

        # Store static covariates and hierarchy in attributes (potentially storing None)
        self._xa = _xarray_with_attrs(self._xa, static_covariates, hierarchy)

    """
    Factory Methods
    ===============
    """

    @classmethod
    def from_xarray(
        cls,
        xa: xr.DataArray,
        fill_missing_dates: Optional[bool] = False,
        freq: Optional[Union[str, int]] = None,
        fillna_value: Optional[float] = None,
    ) -> Self:
        """
        Return a TimeSeries instance built from an xarray DataArray.
        The dimensions of the DataArray have to be (time, component, sample), in this order. The time
        dimension can have an arbitrary name, but component and sample must be named "component" and "sample",
        respectively.

        The first dimension (time), and second dimension (component) must be indexed (i.e., have coordinates).
        The time must be indexed either with a pandas DatetimeIndex, a pandas RangeIndex, or a pandas Index that can
        be converted to a RangeIndex. It is better if the index has no holes; alternatively setting
        `fill_missing_dates` can in some cases solve these issues (filling holes with NaN, or with the provided
        `fillna_value` numeric value, if any).

        If two components have the same name or are not strings, this method will disambiguate the components
        names by appending a suffix of the form "<name>_N" to the N-th column with name "name".
        The component names in the static covariates and hierarchy (if any) are *not* disambiguated.

        Parameters
        ----------
        xa
            The xarray DataArray
        fill_missing_dates
            Optionally, a boolean value indicating whether to fill missing dates (or indices in case of integer index)
            with NaN values. This requires either a provided `freq` or the possibility to infer the frequency from the
            provided timestamps. See :meth:`_fill_missing_dates() <TimeSeries._fill_missing_dates>` for more info.
        freq
            Optionally, a string or integer representing the frequency of the underlying index. This is useful in order
            to fill in missing values if some dates are missing and `fill_missing_dates` is set to `True`.
            If a string, represents the frequency of the pandas DatetimeIndex (see `offset aliases
            <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`_ for more info on
            supported frequencies).
            If an integer, represents the step size of the pandas Index or pandas RangeIndex.
        fillna_value
            Optionally, a numeric value to fill missing values (NaNs) with.

        Returns
        -------
        TimeSeries
            A univariate or multivariate deterministic TimeSeries constructed from the inputs.
        """
        xa_index = xa.get_index(xa.dims[0])

        has_datetime_index = isinstance(xa_index, pd.DatetimeIndex)
        has_range_index = isinstance(xa_index, pd.RangeIndex)
        has_integer_index = not (has_datetime_index or has_range_index)

        has_frequency = (
            has_datetime_index and xa_index.freq is not None
        ) or has_range_index

        # optionally fill missing dates; do it only when there is a DatetimeIndex (and not a RangeIndex)
        if fill_missing_dates:
            xa_ = cls._fill_missing_dates(xa, freq=freq)
        # provided index does not have a freq; using the provided freq
        elif (
            (has_datetime_index or has_integer_index)
            and freq is not None
            and not has_frequency
        ):
            xa_ = cls._restore_xarray_from_frequency(xa, freq=freq)
        # index is an integer index and no freq is provided; try convert it to pd.RangeIndex
        elif has_integer_index and freq is None:
            xa_ = cls._integer_to_range_indexed_xarray(xa)
        else:
            xa_ = xa
        if fillna_value is not None:
            xa_ = xa_.fillna(fillna_value)

        # clean components (columns) names if needed (if names are not unique, or not strings)
        components = xa_.get_index(DIMS[1])
        if len(set(components)) != len(components) or any(
            [not isinstance(s, str) for s in components]
        ):

            def _clean_component_list(columns) -> List[str]:
                # return a list of string containing column names
                # make each column name unique in case some columns have the same names
                clist = columns.to_list()

                # convert everything to string if needed
                for i, column in enumerate(clist):
                    if not isinstance(column, str):
                        clist[i] = str(column)

                has_duplicate = len(set(clist)) != len(clist)
                while has_duplicate:
                    # we may have to loop several times (e.g. we could have columns ["0", "0_1", "0"] and not
                    # noticing when renaming the last "0" into "0_1" that "0_1" already exists...)
                    name_to_occurence = defaultdict(int)
                    for i, column in enumerate(clist):
                        name_to_occurence[clist[i]] += 1

                        if name_to_occurence[clist[i]] > 1:
                            clist[i] = clist[i] + "_{}".format(
                                name_to_occurence[clist[i]] - 1
                            )

                    has_duplicate = len(set(clist)) != len(clist)

                return clist

            time_index_name = xa_.dims[0]
            columns_list = _clean_component_list(components)

            # Note: an option here could be to also rename the component names in the static covariates
            # and/or hierarchy, if any. However, we decide not to do so as those are directly dependent on the
            # component names to work properly, so in case there's any name conflict it's better solved
            # by the user than handled by silent renaming, which can change the way things work.

            # TODO: is there a way to just update the component index without re-creating a new DataArray?
            xa_ = xr.DataArray(
                xa_.values,
                dims=xa_.dims,
                coords={
                    time_index_name: xa_.get_index(time_index_name),
                    DIMS[1]: columns_list,
                },
                attrs=xa_.attrs,
            )

        # We cast the array to float
        if np.issubdtype(xa_.values.dtype, np.float32) or np.issubdtype(
            xa_.values.dtype, np.float64
        ):
            return cls(xa_)
        else:
            return cls(xa_.astype(np.float64))

    @classmethod
    def from_csv(
        cls,
        filepath_or_buffer,
        time_col: Optional[str] = None,
        value_cols: Optional[Union[List[str], str]] = None,
        fill_missing_dates: Optional[bool] = False,
        freq: Optional[Union[str, int]] = None,
        fillna_value: Optional[float] = None,
        static_covariates: Optional[Union[pd.Series, pd.DataFrame]] = None,
        hierarchy: Optional[Dict] = None,
        **kwargs,
    ) -> Self:
        """
        Build a deterministic TimeSeries instance built from a single CSV file.
        One column can be used to represent the time (if not present, the time index will be a RangeIndex)
        and a list of columns `value_cols` can be used to indicate the values for this time series.

        Parameters
        ----------
        filepath_or_buffer
            The path to the CSV file, or the file object; consistent with the argument of `pandas.read_csv` function
        time_col
            The time column name. If set, the column will be cast to a pandas DatetimeIndex (if it contains
            timestamps) or a RangeIndex (if it contains integers).
            If not set, the pandas RangeIndex will be used.
        value_cols
            A string or list of strings representing the value column(s) to be extracted from the CSV file. If set to
            `None`, all columns from the CSV file will be used (except for the time_col, if specified)
        fill_missing_dates
            Optionally, a boolean value indicating whether to fill missing dates (or indices in case of integer index)
            with NaN values. This requires either a provided `freq` or the possibility to infer the frequency from the
            provided timestamps. See :meth:`_fill_missing_dates() <TimeSeries._fill_missing_dates>` for more info.
        freq
            Optionally, a string or integer representing the frequency of the underlying index. This is useful in order
            to fill in missing values if some dates are missing and `fill_missing_dates` is set to `True`.
            If a string, represents the frequency of the pandas DatetimeIndex (see `offset aliases
            <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`_ for more info on
            supported frequencies).
            If an integer, represents the step size of the pandas Index or pandas RangeIndex.
        fillna_value
            Optionally, a numeric value to fill missing values (NaNs) with.
        static_covariates
            Optionally, a set of static covariates to be added to the TimeSeries. Either a pandas Series or a pandas
            DataFrame. If a Series, the index represents the static variables. The covariates are globally 'applied'
            to all components of the TimeSeries. If a DataFrame, the columns represent the static variables and the
            rows represent the components of the uni/multivariate TimeSeries. If a single-row DataFrame, the covariates
            are globally 'applied' to all components of the TimeSeries. If a multi-row DataFrame, the number of
            rows must match the number of components of the TimeSeries (in this case, the number of columns in the CSV
            file). This adds control for component-specific static covariates.
        hierarchy
            Optionally, a dictionary describing the grouping(s) of the time series. The keys are component names, and
            for a given component name `c`, the value is a list of component names that `c` "belongs" to. For instance,
            if there is a `total` component, split both in two divisions `d1` and `d2` and in two regions `r1` and `r2`,
            and four products `d1r1` (in division `d1` and region `r1`), `d2r1`, `d1r2` and `d2r2`, the hierarchy would
            be encoded as follows.

            .. highlight:: python
            .. code-block:: python

                hierarchy={
                    "d1r1": ["d1", "r1"],
                    "d1r2": ["d1", "r2"],
                    "d2r1": ["d2", "r1"],
                    "d2r2": ["d2", "r2"],
                    "d1": ["total"],
                    "d2": ["total"],
                    "r1": ["total"],
                    "r2": ["total"]
                }
            ..
            The hierarchy can be used to reconcile forecasts (so that the sums of the forecasts at
            different levels are consistent), see `hierarchical reconciliation
            <https://unit8co.github.io/darts/generated_api/darts.dataprocessing.transformers.reconciliation.html>`_.

        **kwargs
            Optional arguments to be passed to `pandas.read_csv` function

        Returns
        -------
        TimeSeries
            A univariate or multivariate deterministic TimeSeries constructed from the inputs.
        """

        df = pd.read_csv(filepath_or_buffer=filepath_or_buffer, **kwargs)
        return cls.from_dataframe(
            df=df,
            time_col=time_col,
            value_cols=value_cols,
            fill_missing_dates=fill_missing_dates,
            freq=freq,
            fillna_value=fillna_value,
            static_covariates=static_covariates,
            hierarchy=hierarchy,
        )


### Assistant
class TimeSeries:
    def __init__(self, xa: xr.DataArray):
        """
        Create a TimeSeries from a (well formed) DataArray.
        It is recommended to use the factory methods to create TimeSeries instead.

        See Also
        --------
        TimeSeries.from_dataframe : Create from a :class:`pandas.DataFrame`.
        TimeSeries.from_group_dataframe : Create multiple TimeSeries by groups from a :class:`pandas.DataFrame`.
        TimeSeries.from_series : Create from a :class:`pandas.Series`.
        TimeSeries.from_values : Create from a NumPy :class:`ndarray`.
        TimeSeries.from_times_and_values : Create from a time index and a Numpy :class:`ndarray`.
        TimeSeries.from_csv : Create from a CSV file.
        TimeSeries.from_json : Create from a JSON file.
        TimeSeries.from_xarray : Create from an :class:`xarray.DataArray`.
        """
        raise_if_not(
            isinstance(xa, xr.DataArray),
            "Data must be provided as an xarray DataArray instance. "
            "If you need to create a TimeSeries from another type "
            "(e.g. a DataFrame), look at TimeSeries factory methods "
            "(e.g. TimeSeries.from_dataframe(), "
            "TimeSeries.from_xarray(), TimeSeries.from_values()"
            "TimeSeries.from_times_and_values(), etc...).",
            logger,
        )
        raise_if_not(
            len(xa.shape) == 3,
            f"TimeSeries require DataArray of dimensionality 3 ({DIMS}).",
            logger,
        )

        # Ideally values should be np.float, otherwise certain functionalities like diff()
        # relying on np.nan (which is a float) won't work very properly.
        raise_if_not(
            np.issubdtype(xa.values.dtype, np.number),
            "The time series must contain numeric values only.",
            logger,
        )

        val_dtype = xa.values.dtype
        if not (
            np.issubdtype(val_dtype, np.float64) or np.issubdtype(val_dtype, np.float32)
        ):
            logger.warning(
                "TimeSeries is using a numeric type different from np.float32 or np.float64. "
                "Not all functionalities may work properly. It is recommended casting your data to floating "
                "point numbers before using TimeSeries."
            )

        if xa.dims[-2:] != DIMS[-2:]:
            # The first dimension represents the time and may be named differently.
            raise_log(
                ValueError(
                    "The last two dimensions of the DataArray must be named {}".format(
                        DIMS[-2:]
                    )
                ),
                logger,
            )

        # check that columns/component names are unique
        components = xa.get_index(DIMS[1])
        raise_if_not(
            len(set(components)) == len(components),
            "The components (columns) names must be unique. Provided: {}".format(
                components
            ),
            logger,
        )

        self._time_dim = str(
            xa.dims[0]
        )  # how the time dimension is named; we convert hashable to string

        # The following sorting returns a copy, which we are relying on.
        # As of xarray 0.18.2, this sorting discards the freq of the index for some reason
        # https://github.com/pydata/xarray/issues/5466
        # We sort only if the time axis is not already sorted (monotonically increasing).
        self._xa = self._sort_index(xa, copy=True)

        self._time_index = self._xa.get_index(self._time_dim)

        if not isinstance(self._time_index, VALID_INDEX_TYPES):
            raise_log(
                ValueError(
                    "The time dimension of the DataArray must be indexed either with a DatetimeIndex "
                    "or with an RangeIndex."
                ),
                logger,
            )

        self._has_datetime_index = isinstance(self._time_index, pd.DatetimeIndex)

        if self._has_datetime_index:
            freq_tmp = xa.get_index(
                self._time_dim
            ).freq  # store original freq (see bug of sortby() above).
            self._freq: pd.DateOffset = (
                freq_tmp
                if freq_tmp is not None
                else to_offset(self._xa.get_index(self._time_dim).inferred_freq)
            )
            raise_if(
                self._freq is None,
                "The time index of the provided DataArray is missing the freq attribute, and the frequency could "
                "not be directly inferred. "
                "This probably comes from inconsistent date frequencies with missing dates. "
                "If you know the actual frequency, try setting `fill_missing_dates=True, freq=actual_frequency`. "
                "If not, try setting `fill_missing_dates=True, freq=None` to see if a frequency can be inferred.",
                logger,
            )

            self._freq_str: str = self._freq.freqstr

            # reset freq inside the xarray index (see bug of sortby() above).
            self._xa.get_index(self._time_dim).freq = self._freq

            # We have to check manually if the index is complete for non-empty series. Another way could
            # be to rely on `inferred_freq` being present, but this fails for series of length < 3.
            if len(self._time_index) > 0:
                is_index_complete = (
                    len(
                        pd.date_range(
                            self._time_index.min(),
                            self._time_index.max(),
                            freq=self._freq,
                        ).difference(self._time_index)
                    )
                    == 0
                )

                raise_if_not(
                    is_index_complete,
                    "Not all timestamps seem to be present in the time index. Does "
                    "the series contain holes? If you are using a factory method, "
                    "try specifying `fill_missing_dates=True` "
                    "or specify the `freq` parameter.",
                    logger,
                )
        else:
            self._freq: int = self._time_index.step
            self._freq_str = None

        # check static covariates
        static_covariates = self._xa.attrs.get(STATIC_COV_TAG, None)
        raise_if_not(
            isinstance(static_covariates, (pd.Series, pd.DataFrame))
            or static_covariates is None,
            "`static_covariates` must be either a pandas Series, DataFrame or None",
            logger,
        )
        # check if valid static covariates for multivariate TimeSeries
        if isinstance(static_covariates, pd.DataFrame):
            n_components = len(static_covariates)
            raise_if(
                n_components > 1 and n_components != self.n_components,
                "When passing a multi-row pandas DataFrame, the number of rows must match the number of "
                "components of the TimeSeries object (multi-component/multi-row static covariates must map to each "
                "TimeSeries component).",
                logger,
            )
            static_covariates = static_covariates.copy()
        elif isinstance(static_covariates, pd.Series):
            static_covariates = static_covariates.to_frame().T
        else:  # None
            pass

        # prepare static covariates:
        if static_covariates is not None:
            static_covariates.index = (
                self.components
                if len(static_covariates) == self.n_components
                else [DEFAULT_GLOBAL_STATIC_COV_NAME]
            )
            static_covariates.columns.name = STATIC_COV_TAG
            # convert numerical columns to same dtype as series
            # we get all numerical columns, except those that have right dtype already
            cols_to_cast = static_covariates.select_dtypes(
                include=np.number, exclude=self.dtype
            ).columns

            changes = {col: self.dtype for col in cols_to_cast}
            # Calling astype is costly even when there's no change...
            if len(changes) > 0:
                static_covariates = static_covariates.astype(changes, copy=False)

        # handle hierarchy
        hierarchy = self._xa.attrs.get(HIERARCHY_TAG, None)
        self._top_level_component = None
        self._bottom_level_components = None
        if hierarchy is not None:
            raise_if_not(
                isinstance(hierarchy, dict),
                "The hierarchy must be a dict mapping (non-top) component names to their parent(s) in the hierarchy.",
            )
            # pre-compute grouping informations
            components_set = set(self.components)
            children = set(hierarchy.keys())

            # convert string ancestors to list of strings
            hierarchy = {
                k: ([v] if isinstance(v, str) else v) for k, v in hierarchy.items()
            }

            raise_if_not(
                all(c in components_set for c in children),
                "The keys of the hierarchy must be time series components",
            )
            ancestors = set().union(*hierarchy.values())
            raise_if_not(
                all(a in components_set for a in ancestors),
                "The values of the hierarchy must only contain component names matching those of the series.",
            )
            hierarchy_top = components_set - children
            raise_if_not(
                len(hierarchy_top) == 1,
                "The hierarchy must be such that only one component does "
                + "not appear as a key (the top level component).",
            )
            self._top_level_component = hierarchy_top.pop()
            raise_if_not(
                self._top_level_component in ancestors,
                "Invalid hierarchy. Component {} appears as it should be top-level, but "
                + "does not appear as an ancestor in the hierarchy dict.",
            )
            bottom_level = components_set - ancestors

            # maintain the same order as the original components
            self._bottom_level_components = [
                c for c in self.components if c in bottom_level
            ]

        # Store static covariates and hierarchy in attributes (potentially storing None)
        self._xa = _xarray_with_attrs(self._xa, static_covariates, hierarchy)
###AI-END-DOC###

### Example 3 End
{user_message}

### Assistant
